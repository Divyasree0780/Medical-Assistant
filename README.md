# ðŸ©º Medical Chatbot with RAG (Retrieval-Augmented Generation)

This project implements a **Medical Assistant Chatbot** powered by **LLaMA 3-70B**, **PubMedBERT embeddings**, and **Qdrant Vector Database** using a **Retrieval-Augmented Generation (RAG)** pipeline. The chatbot retrieves contextually relevant medical information and generates factual, context-based answers without fabricating responses.

---

## ðŸš€ Features

* **Retrieval-Augmented Generation (RAG)** for accurate, context-aware answers.
* **PubMedBERT embeddings** for high-quality biomedical text understanding.
* **Qdrant** as a vector store for efficient semantic search.
* **LLaMA 3-70B** for large-scale, high-quality text generation via Groq API.
* **Streamlit UI** for interactive conversations.
* **Session memory** for chat continuity.
* Built-in safety:

  * Only answers based on retrieved context.
  * Avoids giving medical diagnoses or false information.

---

## ðŸ› ï¸ Tech Stack

* **LangChain** â€“ Orchestrating embeddings, retrieval, and LLM pipeline.
* **PubMedBERT** â€“ Domain-specific embeddings for biomedical text.
* **Qdrant** â€“ Vector database for storing and retrieving embeddings.
* **LLaMA 3-70B** â€“ Large language model for answer generation (via Groq API).
* **Streamlit** â€“ Web app interface.
* **Hugging Face Hub** â€“ Embedding and model access.
* **Evaluation Metrics** â€“ BLEU, ROUGE for text evaluation.

---

## ðŸ“¦ Installation

### 1ï¸âƒ£ Clone the repository

```bash
git clone https://github.com/Divyasree0780/Medical-Assistant.git
cd medical-chatbot-rag
```

### 2ï¸âƒ£ Create and activate a virtual environment

```bash
python -m venv venv
source venv/bin/activate   # Linux/Mac
venv\Scripts\activate      # Windows
```

### 3ï¸âƒ£ Install dependencies

```bash
pip install -r requirements.txt
python -m nltk.downloader punkt
```

### 4ï¸âƒ£ Set environment variables

set environment variables:

```env
qdrant_url=YOUR_QDRANT_URL
qdrant_api_key=YOUR_QDRANT_API_KEY
GROQ_API_KEY=YOUR_GROQ_API_KEY
HF_TOKEN=YOUR_HUGGINGFACE_TOKEN
```

---

## ðŸ“‚ Project Structure

```
ðŸ“¦ medical-chatbot-rag
 â”£ ðŸ“œ app.py                 # Main Streamlit app
 â”£ ðŸ“œ requirements.txt       # Project dependencies
 â”£ ðŸ“œ README.md              # Documentation
 â”£ ðŸ“‚ data                   # PDF of medical text data
 â”£ ðŸ“‚ Research               # Research jupyter file
```

---

## âš™ï¸ How It Works

1. **Document Loading**

   * PDFs or medical text files are loaded using `PyPDFLoader` or `DirectoryLoader`.
2. **Text Processing**

   * Text is split into chunks with `RecursiveCharacterTextSplitter`.
3. **Embedding**

   * PubMedBERT converts chunks into vector embeddings.
4. **Vector Storage**

   * Qdrant stores embeddings for fast retrieval.
5. **Query Handling**

   * User queries are embedded and matched using cosine similarity.
6. **Context + LLaMA 3-70B**

   * Retrieved documents are fed into LLaMA for generating final answers.
7. **Streamlit Chat Interface**

   * Conversation is displayed and stored in session memory.

---

## â–¶ï¸ Run the Chatbot

```bash
streamlit run app.py
```

Open your browser and go to **[http://localhost:8501](http://localhost:8501)**.

---

## ðŸ“Š Evaluation

This project uses:

* **BLEU score** â€“ Measures similarity between generated and reference text.
* **ROUGE score** â€“ Measures recall and precision for text overlap.

---

## âš ï¸ Disclaimer

> This chatbot is **not** a substitute for professional medical advice.
> It provides responses based only on the retrieved context and should be used for **educational purposes only**.

---

## ðŸ“œ License

MIT License Â© 2025 Divyasree Harikrishnan

---

